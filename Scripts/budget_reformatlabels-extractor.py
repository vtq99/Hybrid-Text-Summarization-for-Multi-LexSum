# -*- coding: utf-8 -*-
"""Budget reformatlabels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1prhUqXgR8DXur4fIXHaP0EBiq25VQQWh
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture         
# !pip install datasets==1.2.1
# !pip install transformers==4.2.0
# !pip install rouge_score
# !pip install tqdm
from datasets import load_dataset, load_metric
from rouge_score import rouge_scorer
from transformers import LEDTokenizer
import json

######################## CHANGE HERE AND CHANGE THE RESULTING FILE NAME ACCORDINGLY 
data_type = "primera" 
# data_type = "led"

if(data_type=="primera"):
  print("Using 4000 budget and Primera tokenizer")
  tokenizer = LEDTokenizer.from_pretrained("allenai/PRIMERA")
  BUDGET = 4000

elif(data_type=="led"):
  print("Using 16000 budget and LED tokenizer")
  tokenizer = LEDTokenizer.from_pretrained("allenai/led-base-16384")
  BUDGET = 16000

def rouge2_scorer(sentence, target):
  return rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True).score(sentence, target)['rouge2'].recall

source = open("data_full/test_final.jsonl", "r")

lines = source.readlines()
source.close()

clean_dataset = open("test_full_formattated_4K_extractor2.jsonl", "w")
print(" ")
line_counter=0
for line in lines:
    print("Sample ", line_counter)
    line_counter+=1
    json_line = json.loads(line)

    new_format = dict()

    source = json_line.get("source")
    new_format["target"] = json_line.get("summary")
    new_format["source"] = json_line.get("source")
    extracted_lines = []
    dct = [(0,0)]
    
    for key in json_line["label"].keys():
        for slt in json_line["label"][key]:
          dct.append((key,slt))
          extracted_lines += [source[str(key)][slt]]

    # print(" ")
    # print("Original json_line[label]", json_line["label"])
    dct=dct[1:]

    scores = []
    scores_new = []
    idx=0
    for extracted_line in extracted_lines:
      scores.append((idx, extracted_line, rouge2_scorer(extracted_line, json_line.get("summary"))))

      scores_new.append((idx, extracted_line, rouge2_scorer(extracted_line, json_line.get("summary")), dct[idx]))
      idx+=1

    scores_sorted = sorted(scores_new, key=lambda x: x[2], reverse=True)
    
    ordered_budget = []
    budget_extracted_lines = ''
    count = 0
    for idx, sentence, _ , dct in scores_sorted:
      if len(tokenizer(budget_extracted_lines + sentence).get("input_ids")) < BUDGET:
        budget_extracted_lines += sentence
        budget_extracted_lines += " "
        count += 1
        ordered_budget.append((idx,sentence,dct))
      else:
        break
   
    ordered_budget_final = sorted(ordered_budget, key=lambda x: x[0], reverse=False)
    final_sentences = ''

    size_sources = int(ordered_budget_final[-1][2][0])
    selected_dct = {str(i): [] for i in range((size_sources+1))}

    temp_arr=[]
    for _ , sentence, dct in ordered_budget_final:
      final_sentences += sentence
      final_sentences += " "
      temp_arr.append(dct)

    for tuple_item in temp_arr:
      key = tuple_item[0]
      value=tuple_item[1]

      selected_dct[key] = sorted(list(set(selected_dct[key] + [value])))
    # print(" ")
    # print("After budgeting:",selected_dct)
    
    print("Before ",len(scores_sorted),"After ", count)
    print("Length", len(tokenizer(budget_extracted_lines).get("input_ids")))

    new_format["label"]  = selected_dct 
    new_format["proxy"] = final_sentences
  
    clean_dataset.write(json.dumps(new_format) + "\n" )

clean_dataset.close()