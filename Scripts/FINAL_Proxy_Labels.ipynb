{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na49hPKyAbPs",
        "outputId": "e4870e3f-eecd-438a-faac-5ab39213be69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uOQU6gU-T3S"
      },
      "outputs": [],
      "source": [
        "# Select the type of Rouge Score\n",
        "TYPES = ['RL', 'R1', 'R2']\n",
        "\n",
        "chosen_rouge = 'R1' # Edit this line\n",
        "\n",
        "if not chosen_rouge in TYPES:\n",
        "  raise ValueError(\"Not valid Rouge Score\")\n",
        "\n",
        "if chosen_rouge == 'RL':\n",
        "  folder_name = 'R-L'\n",
        "elif chosen_rouge == 'R2':\n",
        "  folder_name = 'R2'\n",
        "else:\n",
        "  folder_name = 'R1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV1Y-DlY9mNE"
      },
      "outputs": [],
      "source": [
        "f = open('drive/MyDrive/Text Summarization (Dataset and labels)/R1/train.jsonl', 'w')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W930htK5Y9aU"
      },
      "outputs": [],
      "source": [
        "# Install depencencies\n",
        "!pip install datasets\n",
        "!pip install nltk\n",
        "!pip install rouge-score\n",
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "!pip install python-crfsuite\n",
        "!pip install Flask\n",
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-GKtZIfZEzB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "import re\n",
        "import scipy.stats as ss\n",
        "import bert_score\n",
        "import pycrfsuite\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Load Multi-lexsum dataset, ETA is circa 2 mins\n",
        "from datasets import load_dataset\n",
        "\n",
        "multi_lexsum = load_dataset(\"allenai/multi_lexsum\", name=\"v20220616\")\n",
        "\n",
        "train_dataset = multi_lexsum['train']\n",
        "val_dataset = multi_lexsum['validation']\n",
        "test = multi_lexsum['test']\n",
        "# Download multi_lexsum locally and load it as a Dataset object "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-base-16384\")"
      ],
      "metadata": {
        "id": "ePvI9I_0zsxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXUTBG4PZG2e"
      },
      "outputs": [],
      "source": [
        "def bert_scorer(sentence, target):\n",
        "  bert_scorer = bert_score.BERTScorer(lang=\"en\", model_type='amazon/bort')\n",
        "  return bert_scorer.score([sentence], [target])[0][0]\n",
        "\n",
        "def rouge1_scorer(sentence, target):\n",
        "   return rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True).score(sentence, target)['rouge1'].recall\n",
        "\n",
        "def rouge2_scorer(sentence, target):\n",
        "  # print('candidate: ', sentence)\n",
        "  return rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True).score(sentence, target)['rouge2'].recall\n",
        "\n",
        "def rougeL_scorer(sentence, target):\n",
        "   return rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True).score(sentence, target)['rougeL'].recall\n",
        "\n",
        "scorer_dict = {'bert': bert_scorer,\n",
        "               'rouge1': rouge1_scorer,\n",
        "               'rouge2': rouge2_scorer,\n",
        "               'rougeL': rougeL_scorer\n",
        "              }\n",
        "              \n",
        "# Sentence tokenizer code starts here\n",
        "LOWER_CHAR = re.compile('[a-z]')\n",
        "UPPER_CHAR = re.compile('[A-Z]')\n",
        "SINGLE_DIGIT = re.compile('\\\\d')\n",
        "WS = re.compile('^[ \\\\t]]+$')\n",
        "LB_WS = re.compile('^[\\\\n\\\\r\\\\v\\\\f]+$')\n",
        "\n",
        "\n",
        "def text2sentences(text, offsets=False):\n",
        "    tokenizer = re.compile(r'[A-z]+|\\d+|[ \\t\\f]+|[\\n\\r\\v]+|[^A-z\\d\\s]')\n",
        "    matches = [match for match in tokenizer.finditer(text)]\n",
        "    preds = tokens2preds([match.group() for match in matches])\n",
        "    indices = preds2sentences(matches, preds)\n",
        "    if offsets:\n",
        "        return indices\n",
        "    else:\n",
        "        return [text[indice[0]:indice[1]] for indice in indices]\n",
        "\n",
        "\n",
        "def preds2sentences(matches, preds):\n",
        "    indices = []\n",
        "    in_annotation = False\n",
        "    start, end = (0, 0)\n",
        "    for label, match in zip(preds, matches):\n",
        "        if label != 'O':\n",
        "            if in_annotation:\n",
        "                end = match.end()\n",
        "            else:\n",
        "                in_annotation = True\n",
        "                start = match.start()\n",
        "                end = match.end()\n",
        "        else:\n",
        "            if in_annotation:\n",
        "                in_annotation = False\n",
        "                indices.append((start, end))\n",
        "    if in_annotation:\n",
        "        indices.append((start, end))\n",
        "    return indices\n",
        "\n",
        "\n",
        "def tokens2preds(tokens):\n",
        "    features = [word2features(tokens, i, 3) for i, token\n",
        "                in enumerate(tokens)]\n",
        "    tagger = init_crf_model('20180904.crfsuite')\n",
        "    return tagger.tag(features)\n",
        "\n",
        "\n",
        "def word2features(doc, i, n, extras=None):\n",
        "    if not extras:\n",
        "        extras = []\n",
        "    features = [\"bias\"]\n",
        "    for n_idx in range(0, n+1):\n",
        "        if i+n_idx < len(doc):\n",
        "            features.extend(token2features(token=doc[i+n_idx], i=n_idx))\n",
        "        elif i+n_idx == len(doc):\n",
        "            features.append(str(n_idx) + ':EOS')\n",
        "    for n_idx in range(-n, 0):\n",
        "        if i+n_idx >= 0:\n",
        "            features.extend(token2features(token=doc[i + n_idx], i=n_idx))\n",
        "        elif i+n_idx == -1:\n",
        "            features.append(str(n_idx) + ':BOS')\n",
        "    return features\n",
        "\n",
        "\n",
        "def token2features(token, i):\n",
        "    return [\n",
        "        str(i) + \":word.lower=\" + token.lower(),\n",
        "        str(i) + \":word.sig=\" + create_token_sig(token),\n",
        "        str(i) + \":word.length=\" + get_token_length(token),\n",
        "        str(i) + \":word.islower=\" + str(token.islower()),\n",
        "        str(i) + \":word.isupper=\" + str(token.isupper()),\n",
        "        str(i) + \":word.istitle=\" + str(token.istitle()),\n",
        "        str(i) + \":word.isdigit=\" + str(token.isdigit()),\n",
        "        str(i) + \":word.iswhitespace=\" + str(token.isspace())\n",
        "    ]\n",
        "\n",
        "\n",
        "def create_token_sig(token):\n",
        "    token = LOWER_CHAR.sub('c', token)\n",
        "    token = UPPER_CHAR.sub('C', token)\n",
        "    token = SINGLE_DIGIT.sub('D', token)\n",
        "    ws_match = WS.match(token)\n",
        "    ln_ws_match = LB_WS.match(token)\n",
        "    if ws_match:\n",
        "        if ws_match.end()-ws_match.start() < 2:\n",
        "            token = 'singlehws'\n",
        "        elif ws_match.end()-ws_match.start() < 5:\n",
        "            token = 'shorthws'\n",
        "        elif ws_match.end()-ws_match.start() < 10:\n",
        "            token = 'hws'\n",
        "        else:\n",
        "            token = 'longhws'\n",
        "    if ln_ws_match:\n",
        "        if ln_ws_match.end() - ln_ws_match.start() < 2:\n",
        "            token = 'singlevws'\n",
        "        elif ln_ws_match.end() - ln_ws_match.start() < 3:\n",
        "            token = 'doublevws'\n",
        "        elif ln_ws_match.end() - ln_ws_match.start() < 4:\n",
        "            token = 'triplevws'\n",
        "        else:\n",
        "            token = 'longvws'\n",
        "    return token\n",
        "\n",
        "\n",
        "def get_token_length(token):\n",
        "    length = len(token)\n",
        "    if length < 4:\n",
        "        return str(length)\n",
        "    elif length < 7:\n",
        "        return 'normal'\n",
        "    else:\n",
        "        return 'long'\n",
        "\n",
        "\n",
        "def init_crf_model(model_type):\n",
        "    # tagger = pycrfsuite.Tagger()\n",
        "    \n",
        "    # model_path = os.path.join('', '', model_type)\n",
        "    # tagger.open(model_path)\n",
        "\n",
        "    tagger = pycrfsuite.Tagger()\n",
        "    import requests\n",
        "    model_path = \"20180904.crfsuite\"\n",
        "    with open(model_path, 'wb' ) as fw:\n",
        "        file_path = requests.get(\"https://github.com/jsavelka/luima_sbd/blob/master/data/20180904.crfsuite?raw=true\")\n",
        "        fw.write(file_path.content)\n",
        "    tagger.open(model_path)\n",
        "\n",
        "    return tagger\n",
        "\n",
        "def preprocess_input(input):\n",
        "  input = re.sub(r'[^a-zA-Z0-9\\.\\!\\? ]', '', input.replace('\\n', ' '))\n",
        "  input = re.sub(r'Page.[0-9].of.[0-9]', '' , input)\n",
        "  # plug removing duplications here\n",
        "  return input\n",
        "\n",
        "def get_sentences(input):\n",
        "  return text2sentences(input)\n",
        "\n",
        "def add_unimportant(selected_dct):\n",
        "\n",
        "  random.seed(5)\n",
        "\n",
        "  selected_dct2 = selected_dct.copy()\n",
        "  # print(selected_dct2)\n",
        "  for key in selected_dct2.keys():\n",
        "    value = selected_dct2[key]\n",
        "    max_sentence_index = value[-1]\n",
        "    unimportant_potential = list(range(0, max_sentence_index+1))\n",
        "    unimportant = sorted((list(set(unimportant_potential) - set(selected_dct2[key]))))\n",
        "    candidates = random.choices(unimportant, k=int(random.choice(range(0, 20))/100*len(selected_dct2[key])))\n",
        "    len_unimportant = len(candidates)\n",
        "    # print(\"candidates: \", candidates)\n",
        "    # print(\"candidate size \", len_unimportant)\n",
        "    # print(random.shuffle(selected_dct2[key]))\n",
        "\n",
        "    # We need to remove equal number of sentences from the selected as much as we are adding\n",
        "    if(len_unimportant>0):\n",
        "      random.shuffle(value)\n",
        "      selected_dct2[key] = sorted(value[:len(value)-len_unimportant])\n",
        "      # print(\"Truncated: \", selected_dct2[key])\n",
        "\n",
        "      selected_dct2[key] = sorted(list(set(selected_dct2[key] + candidates)))\n",
        "\n",
        "  # sorted(random.shuffle(selected_dct2[doc_idx])[:-int(random.choice(range(0, 0.2)*len('assgfhs'))])\n",
        "  # print(\"final:\", selected_dct2)\n",
        "  return selected_dct2\n",
        "\n",
        "\n",
        "def find_max_sentence(sentences, target, scorer):\n",
        "  max_score = 0\n",
        "  i=0\n",
        "  start_index=0\n",
        "  while (i<len(sentences)):\n",
        "    sentence_score = scorer(sentences[i], target)\n",
        "    if sentence_score > max_score:\n",
        "      max_score = sentence_score\n",
        "      start_index = i\n",
        "    i=i+1\n",
        "  return start_index\n",
        "\n",
        "def greedy_search(sentences, paragraph, paragraph_weight, scorer):\n",
        "  start_index = find_max_sentence(sentences, paragraph, scorer)\n",
        "  selected = [start_index]\n",
        "  max_rouge = scorer(paragraph, sentences[start_index])\n",
        "\n",
        "  for i in range(len(sentences)):\n",
        "      score = scorer(paragraph, ' '.join(sentences[slt] for slt in selected) + sentences[i])\n",
        "      new_rouge = score\n",
        "\n",
        "      if new_rouge > max_rouge:\n",
        "          selected.append(i)\n",
        "          max_rouge = new_rouge\n",
        "          total_token_length = 0\n",
        "          for slt in selected:\n",
        "            total_token_length += len(tokenizer(sentences[slt]))\n",
        "          if total_token_length > MAX_TOKEN_SIZE*paragraph_weight:\n",
        "            #print('Reached the limit for this document!')\n",
        "            break\n",
        "          # print(selected)\n",
        "  # selected = sorted(selected)\n",
        "  return selected\n",
        "\n",
        "def get_order(sources, paragraphs, scorer):\n",
        "  order_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "  rank_dct = {i: [] for i in range(len(paragraphs))}\n",
        "  for i in range(len(paragraphs)):\n",
        "    max_score = 0\n",
        "    pos = 0\n",
        "    for j in range(len(sources)):\n",
        "      score = order_scorer.score(paragraphs[i], sources[j])['rougeL'].recall\n",
        "      rank_dct[i] = rank_dct[i] + [score]\n",
        "\n",
        "  # re-rank the dict\n",
        "  order = {}\n",
        "  for key in rank_dct.keys():\n",
        "    # if rouge score is low\n",
        "    # can separate into 3 levels\n",
        "    if sum(rank_dct[key]) < 0.5*len(rank_dct[key]):\n",
        "      order[key] = [None] + (ss.rankdata(rank_dct[key])[::-1] - 1).astype(int).tolist()\n",
        "    else:\n",
        "      order[key] = (ss.rankdata(rank_dct[key])[::-1] - 1).astype(int).tolist()\n",
        "  return order\n",
        "\n",
        "def get_proxy_label(train_idx, scorer, softing=False, unimportant=False, datasplit='train'):\n",
        "  print(train_idx)\n",
        "  sources = multi_lexsum[datasplit][train_idx]['sources']\n",
        "  target = multi_lexsum[datasplit][train_idx]['summary/long']\n",
        "  paragraphs = target.split('\\n\\n')\n",
        "  paragraphs = [paragraph for paragraph in paragraphs if paragraph != '']\n",
        "  order = get_order(sources, paragraphs, scorer)\n",
        "  #print(order)\n",
        "  #print(\"Unimportant flag is :\", unimportant)\n",
        "  selected_dct = {i: [] for i in range(len(sources))}\n",
        "  for priority in range(len(sources)+1):\n",
        "    for paragraph_idx in order.keys():\n",
        "      try:\n",
        "        if order[paragraph_idx][priority] is not None:\n",
        "          doc_idx = order[paragraph_idx][priority]\n",
        "          # print('Priority {}, greedy on paragraph {} and document {}'.format(priority+1, paragraph_idx, doc_idx))\n",
        "          input = preprocess_input(sources[doc_idx])\n",
        "          sentences = get_sentences(input)\n",
        "          candidates = greedy_search(sentences=sentences,\n",
        "                                    paragraph=paragraphs[paragraph_idx],\n",
        "                                    paragraph_weight=len(paragraphs[paragraph_idx].split())/len(target.split()),\n",
        "                                    scorer=scorer)\n",
        "          selected_dct[doc_idx] = sorted(list(set(selected_dct[doc_idx] + candidates)))\n",
        "      except: pass\n",
        "    \n",
        "    token_len = 0\n",
        "    for key in selected_dct.keys():\n",
        "      input = preprocess_input(sources[key])\n",
        "      sentences = get_sentences(input)\n",
        "      for slt in seleced_dct[key]:\n",
        "        token_len += len(tokenizer(sentences[slt]))\n",
        "    #print('Running on Priority {} -> Current token length {}'.format(priority, token_len))\n",
        "    if token_len > MAX_TOKEN_SIZE or token_len > 15*len(target.split()):\n",
        "      break\n",
        "\n",
        "  # Document softing\n",
        "  if softing or token_len < 10*len(target.split()):\n",
        "    print('Searching in other documents')\n",
        "    unlisted = []\n",
        "    for key in selected_dct.keys():\n",
        "      if len(selected_dct[key]) < 1:\n",
        "        unlisted.append(key)\n",
        "    print(unlisted)\n",
        "\n",
        "    for doc_idx in unlisted:\n",
        "      input = preprocess_input(sources[doc_idx])\n",
        "      sentences = get_sentences(input)\n",
        "      for paragraph_idx in range(len(paragraphs)):\n",
        "        candidates = greedy_search(sentences=sentences,\n",
        "                                   paragraph=paragraphs[paragraph_idx],\n",
        "                                   paragraph_weight=len(paragraphs[paragraph_idx].split())/len(target.split())/len(sources),\n",
        "                                   scorer=scorer)\n",
        "        selected_dct[doc_idx] = sorted(list(set(selected_dct[doc_idx] + candidates)))\n",
        "\n",
        "  if unimportant:\n",
        "    print(\"Before unimportant: \", selected_dct)\n",
        "    selected_dct = add_unimportant(selected_dct)\n",
        "    print(\"After unimportant: \", selected_dct)\n",
        "  return selected_dct, sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6CR83dvZJ65"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "MAX_TOKEN_SIZE = 15000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7MxgRuGZMeY",
        "outputId": "34513e7e-29e8-42f5-a5c4-1f662d6b5628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Searching in other documents\n",
            "[]\n",
            "1\n",
            "Searching in other documents\n",
            "[]\n",
            "2\n",
            "Searching in other documents\n",
            "[]\n",
            "3\n",
            "Searching in other documents\n",
            "[0, 9, 11, 12]\n",
            "4\n",
            "Searching in other documents\n",
            "[]\n",
            "5\n",
            "Searching in other documents\n",
            "[]\n",
            "6\n",
            "Searching in other documents\n",
            "[]\n",
            "7\n",
            "Searching in other documents\n",
            "[0]\n",
            "8\n",
            "Searching in other documents\n",
            "[]\n",
            "9\n",
            "Searching in other documents\n",
            "[0]\n",
            "10\n",
            "Searching in other documents\n",
            "[1]\n",
            "11\n",
            "Searching in other documents\n",
            "[0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
            "12\n",
            "Searching in other documents\n",
            "[6, 8, 9, 10, 12, 13]\n",
            "13\n",
            "Searching in other documents\n",
            "[]\n",
            "14\n",
            "Searching in other documents\n",
            "[1, 2]\n",
            "15\n",
            "Searching in other documents\n",
            "[0, 1, 2, 3, 4, 8]\n",
            "16\n",
            "Searching in other documents\n",
            "[0, 2, 3, 4, 7]\n",
            "17\n"
          ]
        }
      ],
      "source": [
        "a=[]\n",
        "b=[]\n",
        "datasets_list = ['train', 'validation', 'test']\n",
        "\n",
        "for data in datasets_list:\n",
        "  store_file = open(f\"drive/MyDrive/Text Summarization (Dataset and labels)/{folder_name}/{data}.jsonl\", \"w\")\n",
        "  for i in range(len(multi_lexsum[data])):\n",
        "    #replace with len dataset\n",
        "    proxy_indices = []\n",
        "    proxy_labels = []\n",
        "    rouge1_scores = []\n",
        "    rouge2_scores = []\n",
        "    rougeL_scores = []\n",
        "    bert_scores = []\n",
        "    paragraphs = dict()\n",
        "    scorers = [rouge1_scorer]\n",
        "\n",
        "    for scorer in scorers:\n",
        "      idx = i\n",
        "      selected_dct, sources = get_proxy_label(train_idx=idx, scorer=scorer, softing=True, datasplit=data)\n",
        "\n",
        "      target = preprocess_input(multi_lexsum[data][idx]['summary/long'])\n",
        "\n",
        "\n",
        "      proxy_indices.append(selected_dct)\n",
        "\n",
        "      # Reconstruct label\n",
        "      for key in range(len(sources)):\n",
        "        input = preprocess_input(sources[key])\n",
        "        sentences = get_sentences(input)\n",
        "        paragraphs[str(key)] = sentences \n",
        "        proxy_label = ' '.join(sentences[slt] for slt in selected_dct[key])\n",
        "        proxy_labels.append(proxy_label)\n",
        "        b.append(proxy_labels)\n",
        "\n",
        "      result = dict()\n",
        "      result[\"summary\"] = target\n",
        "      result[\"source\"] = paragraphs\n",
        "      result[\"label\"] = selected_dct\n",
        "\n",
        "      #print(result)\n",
        "      store_file.write(json.dumps(result) + \"\\n\")\n",
        "\n",
        "  store_file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}