# -*- coding: utf-8 -*-
"""final1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LvH9mMQ6y08fH_v4fcWYEcz8B4KZsMf4
"""

# Install depencencies
#!pip install datasets
#!pip install transformers
#!pip install rouge-score
#import stanza
#stanza.download('en') # download English model
#nlp = stanza.Pipeline('en', use_gpu = True) # initialize English neural pipeline

import nltk
nltk.download('punkt')
import numpy as np
import torch
import json
import os
from datasets import load_dataset
  

# Get dataset: target: string, source: list[list[string]], 
# i.e., list documents, each document is list of sentences.
dataset = MultilexsumDataset()
train_sources = dataset.get_source_sentences(dataset.train)
train_targets = dataset.get_targets(dataset.train)
#validation_sources = dataset.get_source_sentences(dataset.validation)
#validation_targets = dataset.get_targets(dataset.validation)
#test_sources = dataset.get_source_sentences(dataset.test)
#test_targets = dataset.get_targets(dataset.test)


from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel, LEDTokenizer

# Load the BERT model and tokenizer
bert_model_id = "nlpaueb/legal-bert-base-uncased"
bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_id)
bert_model = AutoModel.from_pretrained(bert_model_id)


# Move the BERT model to the GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

# Load the LED tokenizer
led_model_id = "allenai/led-base-16384"
led_tokenizer = LEDTokenizer.from_pretrained(led_model_id)


#------------------------------------------------------------------------------
# Description : Get MMR similariy score for the given sentences.

# Parameters  : sentences: list[string], 
#               indices: list[string], 
#               lambta: float: default(0.5),
#               MAX_LENGTH: int: output source in tokens: default(16384),

# Return      : {'index': list[string]
#                'source': list[string]
#                'MMRScore': list[float]
#               }
#------------------------------------------------------------------------------
def get_scores(sentences, indices, lambta = 0.5, MAX_LENGTH = 16384):
  n = len(sentences)
  mean_pooled_sentences = []
  batch_size = 256
  for i in range(0, n, batch_size):
    batch_sentences = sentences[i : i+batch_size]
    encoded_sentence = bert_tokenizer(batch_sentences,
                                      max_length = 128,
                                      truncation = True, 
                                      padding='max_length',
                                      return_tensors = 'pt'
                                      ).to(device)

    with torch.no_grad():
      sentence_embeddings = bert_model(**encoded_sentence).last_hidden_state
  
    attention_mask = encoded_sentence['attention_mask']
    mask = attention_mask.unsqueeze(-1).expand(sentence_embeddings.size()).float()
    masked_embeddings = sentence_embeddings * mask
    summed = torch.sum(masked_embeddings, 1)
    summed_mask = torch.clamp(mask.sum(1), min=1e-9)
    mean_pooled = summed / summed_mask
    
    mean_pooled_sentences.extend(mean_pooled.detach().cpu().numpy())

  #--------------------------- MMR Score ------------------------------
  # Get MMR score for each sentence s_i in mean_pooled_sentences: list[sentence_embeddings]:
  # argmax[ lambda*cosine_similarity(s_i, query) - (1-lambda)*max(cosine_similarity(s_i, selected_sentences) ]
  #--------------------------------------------------------------------
  
  output = {
      'index': [],
      'MMRScore': [],
      'source': [],
  }

  # Query is the mean of all the sentence embeddings.
  query = np.mean(mean_pooled_sentences, axis = 0)
  
  similarity_scores = cosine_similarity(mean_pooled_sentences, [query])
  
  # The first selected sentence index with the highest similarity score between sentences and query.
  max_index = np.argmax(similarity_scores)

  output['index'].append(indices[max_index])
  output['MMRScore'].append(float(max(similarity_scores)))
  output['source'].append(sentences[max_index])
  
  best_sentence = mean_pooled_sentences[max_index]
  selected_sentences = [best_sentence]
  
  selected_mask = [False for _ in range(n)]
  selected_mask[max_index] = True

  # Length tracker for the selected sentences, stop when it reaches MAX_LENGTH.
  LENGTH_SO_FAR = len(led_tokenizer(sentences[max_index]).get("input_ids"))

  while len(selected_sentences) < n and LENGTH_SO_FAR < MAX_LENGTH:
    MMR_scores = []
    diversity_scores = cosine_similarity(selected_sentences, mean_pooled_sentences).max(axis = 0)

    for i, _ in enumerate(mean_pooled_sentences):  
      if selected_mask[i]:
        # Already selected sentence, set it to lowest score or -inf.
        MMR_scores.append(-1.0)
        continue

      similarity = float(similarity_scores[i])
      l_expr = lambta * similarity      
      diversity = float(diversity_scores[i])
      r_expr = (1-lambta) * diversity
      
      MMR_score = l_expr - r_expr
      MMR_scores.append(MMR_score)

    max_index = np.argmax(MMR_scores)

    selected_sentences.append(mean_pooled_sentences[max_index])
    output['index'].append(indices[max_index])
    output['source'].append(sentences[max_index])
    output['MMRScore'].append(max(MMR_scores))
    
    selected_mask[max_index] = True
    
    LENGTH_SO_FAR += len(led_tokenizer(sentences[max_index]).get("input_ids"))

  return output

#with open('/content/drive/MyDrive/multilexsum_data/train_MMR_LDS.jsonl', 'w') as f:
#  f.close()

for i in range(len(train_sources)):
  source_sentences = []
  indices = []
  for j, doc_sentences in enumerate(train_sources[i]):
    for k, sentence in enumerate(doc_sentences):
      indices.append('d' + str(j) + '_' + str(k))
      source_sentences.append(sentence)
  output = get_scores(source_sentences, indices, lambta=0.6)

  data = {'target': train_targets[i],
          'index': output['index'],
          'source': output['source'],
          'MMRScore': output['MMRScore']
          }
  with open('/content/drive/MyDrive/multilexsum_data/train_MMR_LDS.jsonl', 'a') as f:
    f.write(json.dumps(data) + '\n')
    f.close()
  #print(i, 'src done..')


sources = []
targets = []
indices = []
scores = []
with open('/content/drive/MyDrive/multilexsum_data/train_MMR_LDS.jsonl', 'r') as f:
  for line in f:
    jline = json.loads(line)
    sources.append(jline['source'])
    targets.append(jline['target'])
    indices.append(jline['index'])
    scores.append(jline['MMRScore'])
  f.close()


#--------------------------------------------------------------------
# Map back to the original chronological order of the sentences
# Sentence index is formulate as 'd{document_index}_{sentence_index}', 
# e.g., index 'd1_25' means that this sentences appears in document number 1, sentence number 25.
#--------------------------------------------------------------------

sources_ordered = []
indices_ordered = []
# Define a sorting function that extracts the numbers from the strings and sorts by them
def sort_by_numbers(s):
    num1, num2 = map(int, s[1:].split('_'))
    return (num1, num2)

for i, source in enumerate(sources):
  # Sort the two lists together based on the numbers in the strings
  sorted_lists = list(zip(*sorted(zip(indices[i], source), key=lambda x: sort_by_numbers(x[0]))))

  # Unpack the sorted lists back into separate variables
  indices_ordered.append(sorted_lists[0])
  sources_ordered.append(sorted_lists[1])

n = len(train_sources)
sources_MDS = [[] for i in range(n)]
indices_MDS = [[] for i in range(n)]
for i in range(n):
  for j in range(len(train_sources[i])):
    sources_MDS[i].append([])
    indices_MDS[i].append([])

for i, src in enumerate(indices_ordered):
  for j, v in enumerate(src):
    curr_doc = int(v[1:].split('_')[0])
    sources_MDS[i][curr_doc].append(sources_ordered[i][j])
    indices_MDS[i][curr_doc].append(indices_ordered[i][j])

#---------------------------- Reordering ----------------------------------
# Reorder the documents using rouge score, given the selected sentences from each document.
#--------------------------------------------------------------------------

from rouge_score import rouge_scorer

docs_rouge_score = []
# Rouge score between document d_i and D\{d_i}, RougeScorer(d_i, D\{d_i}).
for i, src in enumerate(sources_MDS):
  s = []
  for j, sentences in enumerate(src):
    other_sentences = []
    src[:j] + src[j+1:]
    for k in range(j):
      other_sentences.extend(src[k])
    for k in range(j+1, len(src)):
      other_sentences.extend(src[k])
    concatenated_other_sentences = ' '.join(other_sentences)
    concatenated_sentences = ' '.join(sentences)

    # RougeScorer(d_i, D\{d_i}).
    rouge_score = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True).score(concatenated_sentences, concatenated_other_sentences)['rouge2'].fmeasure
    sources_MDS[i][j] = concatenated_sentences
    s.append(rouge_score)
  #print(i, ' src done')
  docs_rouge_score.append(s)

for i in range(len(sources_MDS)):
  ordered_src = [x for _, x in sorted(zip(docs_rouge_score[i], sources_MDS[i]), reverse=True)]
  sources_MDS[i] = ' '.join(ordered_src)

with open('/content/drive/MyDrive/multilexsum_data/train_LED_LDS.jsonl', 'w') as f:
  f.close()

# Finally, dataset to be used for abstractive model training.
for i, v in enumerate(sources_MDS):
  with open('/content/drive/MyDrive/multilexsum_data/train_LED_LDS.jsonl', 'a') as f:
    data = {'target': targets[i],
            'source': v
            }
    f.write(json.dumps(data) + '\n')
    f.close()